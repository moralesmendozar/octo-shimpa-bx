{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Aprendizaje de Máquina - ITAM\n",
    "Octubre, 2016\n",
    "\n",
    "\n",
    "MSc. Liliana Millán, liliana.millan@gmail.com\n",
    "\n",
    "![](images/itam_logo.png)\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agenda \n",
    "\n",
    "+ Information Retrieval\n",
    "+ ¿Por qué es importante? \n",
    "+ Métodos/algoritmos para medir relevancia\n",
    "+ Proceso estándar de minado de texto\n",
    "+ Ejemplo de TF/IDF\n",
    "+ Caso de Negocio\n",
    "+ Referencias\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minería de Texto - Information Retrieval (IR)\n",
    "\n",
    "Information Retrieval es una rama de las Ciencias Computacionales que se define como:\n",
    "\n",
    ">\"Ciencia dedicada a encontrar material digital —generalmente documentos— de una naturaleza no estructurada —generalmente textos— de entre una gran cantidad de colecciones —generalmente almacenada en computadoras— que satisfacen una necesidad de información.\" *An Introduction to Information Retrieval*\n",
    "\n",
    "\n",
    "En un sistema de IR hay 3 elementos: \n",
    "\n",
    "1. Una consulta que puede estar formada por más de un término \n",
    "2. Una colección de documentos en donde buscar la consulta\n",
    "3. Ordenar la colección de acuerdo a su relevancia con respecto a la consutla \n",
    "\n",
    "El buscador de Google es un sistema IR, el primer elemento consiste en las palabras que ponemos en el buscador, el segundo elemento corresponde a todas las páginas web, y el tercer elemento corresponde a la respuesta de documentos que regresa Google ordenada descendentemente por relevancia con base a los términos de consulta.\n",
    "\n",
    "\n",
    "## ¿Por qué es importante? ¿En qué se ocupa?\n",
    "\n",
    "¿Cuánto crees que vale Google? --> **$82,500 millones de dólares** *Mayo 2016, Forbes*\n",
    "\n",
    "El algoritmo de [Pagerank](http://infolab.stanford.edu/pub/papers/google.pdf) de Google (1998) fue una de las aplicaciones de IR que cambió el mundo digital y que atrajo a esta disciplina mucho interés. \n",
    "\n",
    "+ **SEO (Search Engine Optimization)**. Etiquetar el contenido de manera correcta para que sea encontrado por un buscador de páginas (Google) y se muestre como un documento relevante —mientras más arriba más relevante... y mayor probabilidad de que te den clic—\n",
    "+ **Clasificación de texto**. Asignar un texto a una categoría generalmente tópicos, estos tópicos pueden ser jerárquicos.\n",
    "+ **Organización de información**. Generar Taxonomías/Ontologías/Grafos de contenidos\n",
    "+ **Recomendación de contenidos**. Una vez que el contenido ha sigo clasificado nos permite hacer recomendaciones de contenidos similares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aproximación al problema\n",
    "\n",
    "Los diferentes modelos de IR cambian de acuerdo a cómo miden la **relevancia** y generalmente se dividen en modelos algebráicos, probabilísticos y de machine learning.\n",
    "\n",
    "+ Algebráicos: Basados en el *Vector Space Model* TF-IDF, distancia coseno, similitud de Jaccard ... \n",
    "+ Probabilísticos: Basados es en el *Binary Independence Model* (BIM): Okapi BM25, LSI, LDA ...\n",
    "+ \\*Machine Learning: Deep Learning uan vez que el problema se convierte a clasificación de texto!\n",
    "\n",
    "\n",
    "### Algebraicos\n",
    "\n",
    "#### Vector Space Model\n",
    "\n",
    "Una forma de representar un documento consiste en *romperlo* en términos —generalmente palabras— que lo conforman, de esta manera cada documento tiene asociado esta representación vectorial $\\vec{x}=(x_{1},...,x_{m})$ de acuerdo a los términos que aparecen en él. \n",
    "\n",
    "A esta representación se le conoce también como **bolsa de palabras** pues al romper el documento en términos suponemos que cada uno ocurre independientemente, sabemos que eso no es cierto y que el orden de las palabras claramente va asociado a un contexto/significado, sin embargo esa sola suposición nos permite generar modelos suficientemente buenos. \n",
    "\n",
    "En los modelos algebráicos la relevancia se mide de acuerdo a la **similaridad** de los documentos al query.\n",
    "\n",
    "#### Jaccard Similarity Coefficient\n",
    "\n",
    "Mide similitud entre conjuntos\n",
    "\n",
    "$$J(A,B)=\\frac{(A \\cap B)}{A \\cup B}$$\n",
    "\n",
    "Ejemplo: A={'una','casa','cama','votos','elefante'}, B={'casa','elefante','leon'} la similitud de Jaccard entre estos dos conjuntos es: \n",
    "\n",
    "$J(A,B)=\\frac{('casa','elefante')}{('una','casa','cama','votos','elefante','leon')}= \\frac{2}{6}=\\frac{1}{3}=0.33$ \n",
    "\n",
    "El conjunto A y B tienen 0.33 de similitud, mientras el número sea más cercano a 1 mayor será la similitud. \n",
    "\n",
    "#### TF/IDF\n",
    "\n",
    "Es el algoritmo más popular para la recuperación de información debido a que su explicación es intuitiva y es muy fácil de implementar. La relevancia de un documento se mide con relación a la frecuencia que el término de consulta aparece en cada documento de la colección y el inverso del número de documentos de la colección en los que aparece el término\n",
    "\n",
    "$$tfidf_{t}=tf_{t,d} \\cdot log\\frac{N}{df}$$\n",
    "\n",
    "Donde: \n",
    "\n",
    "+ $t$: Término de consulta\n",
    "+ $tf$: Frecuencia del término $t$ en el documento $d$\n",
    "+ $N$: Número de documentos en nuestra colección\n",
    "+ $df$: Número de documentos en los que aparece el término\n",
    "+ El logaritmo permite limitar el peso de tener colecciones de documentos muy grandes (generalmente se ocupa en base 10) \n",
    "\n",
    "Cuando se tiene más de un término en la consulta el TF/IDF final de un documento se obtiene sumando el TF/IDF obtenido para cada término en la consulta: \n",
    "\n",
    "$$tfidf_{c,d} = \\sum_{t \\in c} tfidf_{t,d}$$\n",
    " \n",
    "Este modelo ocupa una matriz de términos (renglones) y documentos (columnas) en donde almacenamos la frecuencia de aparición de cada término para cada documento en la colección. Esta matriz toma como base la representación vectorial y generalmente es una matriz *sparse* —con muchos 0s—\n",
    "\n",
    "\n",
    "### Probabilísticos \n",
    "\n",
    "Ocupan la misma representación vectorial de los documentos que los modelos algebraicos pero la relevancia está medida con modelos probabilísticos que estiman que tan probable es que un documento sea relevante a un query —generalmente se ocupa Bayes—\n",
    "\n",
    "#### Binary Independence Retrieval Model (BIM)\n",
    "\n",
    "En este método el vector de un documento toma valores binarios: 1 si el término está en el documento, 0 en otro caso $d=\\vec{x}=(x_{1},...,x_{n})$ $x_{i}=1$ si el término está en el documento d.\n",
    "\n",
    "En este modelo la relevancia de un documento está medida a través Bayes ocupando la incidencia de los términos $\\vec{x}$ en la consulta $\\vec{q}$\n",
    "\n",
    "$P(R|d,q)$ \n",
    "\n",
    "Donde: \n",
    "\n",
    "+ $R$: Relevancia\n",
    "+ $d$: Documento\n",
    "+ $q$: Query\n",
    "\n",
    "\n",
    "Entonces\n",
    "\n",
    "$$P(R=1|\\vec{x},\\vec{q})=\\frac{P(\\vec{x}|R=1,\\vec{q})P(R=1|\\vec{q})}{P(\\vec{x}|\\vec{q})}$$\n",
    "\n",
    "$$P(R=0|\\vec{x},\\vec{q})=\\frac{P(\\vec{x}|R=0,\\vec{q})P(R=0|\\vec{q})}{P(\\vec{x}|\\vec{q})}$$\n",
    "\n",
    "\n",
    "+ $P(\\vec{x}|R=1,\\vec{q})$ y $P(\\vec{x}|R=0,\\vec{q})$: La probabilidad de que si un documento regresado es relevante o irrelavante su representación es $\\vec{x}$\n",
    "+ $P(R=1|\\vec{q})$ y $P(R=0|\\vec{q})$: La probabilidad a priori de haber regresado un documento relevante o no dado el query \n",
    "\n",
    "Debido a que un documento solo puede ser relavante o no $P(R=1|\\vec{x},\\vec{q}) + P(R=0|\\vec{x},\\vec{q})=1$\n",
    "\n",
    "Debido a que nos interesa regresar toda la colección ordenada por relevancia: orden descendiente de $P(R=1|\\vec{x},\\vec{q})$ en lugar de calcular directamente esta probabilidad se ocupan otros valores que regresan el mismo orden.\n",
    "\n",
    "... \n",
    "\n",
    "Para ver los detalles de como se paso de una cosa a otra revisar\n",
    "\n",
    "[Introduction to IR, Deriving a ranking function for query terms](http://nlp.stanford.edu/IR-book/html/htmledition/deriving-a-ranking-function-for-query-terms-1.html) \n",
    "\n",
    "[Introduction to IR, Probability estimates in theory](http://nlp.stanford.edu/IR-book/html/htmledition/probability-estimates-in-theory-1.html)\n",
    "\n",
    "\n",
    "$$log \\frac{s + \\frac{1}{2}/(S-s + \\frac{1}{2})}{df_{t}-s+\\frac{1}{2}/(N-df_{t}-S+s+\\frac{1}{2})}$$\n",
    "\n",
    "+ Se agrega 1/2 para evitar 0's (smoothing)\n",
    "+ En los casos prácticos se asume que los documentos relevantes en una collección son una proporción muy pequeña de la misma y por lo tanto la ecuación anterior toma la forma\n",
    "\n",
    "$$log\\frac{N}{df}$$\n",
    "\n",
    "[Introduction to IR, Probability estimates in practice](http://nlp.stanford.edu/IR-book/html/htmledition/probability-estimates-in-practice-1.html) para la explicación "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#a5d2fb\";>\n",
    "<p>\n",
    "Es el idf de TF/IDF!\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BM25 (Okapi Best Match 25)\n",
    "\n",
    "Este modelo toma en consideración la longitud de los documentos, la longitud del query y la frecuencia del término en el query en 3 parámetros que permiten 'controlar' la influencia que cada uno de estos tendrá en la métrica de relevancia.\n",
    "\n",
    "$$\\sum_{i\\in Q} log\\frac{(r_{i} + 0.5)(N-n_{i}-R+r_{i}+0.5)}{(n_{i}-r_{i}+0.5)(R-r_{i}+0.5)}\\cdot \\frac{(k_{1}+1)f_{i}}{(K+f_{i})} \\cdot \\frac{(k_{2}+1)qf_{i}}{k_{2}+qf_{i}}$$\n",
    "\n",
    "$$K=k_{1}\\left((1-b)+b\\cdot\\frac{dl}{avgdl}\\right)$$\n",
    "\n",
    "\n",
    "+ $avgdl$ Longitud promedio de los documentos de la colección, medido en el \\# de palabras\n",
    "+ $dl$ Longitud de cada documento, medido en el \\# de palabras\n",
    "+ $N$ \\# de documentos que hay en la colección\n",
    "+ $R$ \\# de documentos relevantes en el set, si no contamos con esta información se pone en 0\n",
    "+ $r_{i}$ \\# de documentos relevantes que contienen el término $i$, si no contamos con esta información se pone en 0 \n",
    "+ $n_{i}$ \\# de documentos que contienen el término $i$\n",
    "+ $f_{i}$ La frecuencia del término $i$ en el documento\n",
    "+ $qf_{i}$ La frecuencia del término $i$ en el query\n",
    "+ $k_{1}$ Parámetro que determina cómo la frecuencia del término $i$ afectará a su peso mientras la frecuencia incrementa en cada documento. Si es 0 entonces la frecuencia del término es ignorada. Provoca que $f_{i}$ no sea lineal y que después de 3 o 4 ocurrencias del término tener más ocurrencias tengan poco impacto en la calificación,  $\\in[1.0,2.0]$. De acuerdo a [TREC](http://trec.nist.gov/) un valor típico es de 1.2\n",
    "+ $k_{2}$  Parámetro que controla el peso del término $i$ en la consulta $\\in[0-1000]$. De acuerdo a [TREC](http://trec.nist.gov/) su valor típico bajo, provoca que la calificación de BM25 sea menos sensible a k2 que a k1 ya que las frecuencias de los términos en la cosulta son menores y menos variables que las frecuencias de los términos en los documentos de la colección.\n",
    "+ $K$ Normaliza el componente de frecuencia del término de acuerdo a la longitud del documento.\n",
    "+ $b$ Regulariza el impacto de la normalización realizada con la longitud del documento, $\\in[0,1]$ Si b es 0 no se toma en cuenta la normalización, de acuerdo a [TREC](http://trec.nist.gov/) su valor típico es de 0.75\n",
    "\n",
    "\n",
    "#### Latent Semantic Indexing [LSI](http://nlp.stanford.edu/IR-book/html/htmledition/latent-semantic-indexing-1.html) \n",
    "\n",
    "Este método utiliza la matriz de términos y documentos para hacer un producto punto entre todos los términos y documentos para ocupar un Singular Value Decomposition (SVD) para reducir dimensionalidad... la idea que documentos que tienen palabras similiares son del mismo contexto. Fue de los primero métodos que intentan descubrir contexto —semántica— en los documentos basado en una bolsa de palabras.\n",
    "\n",
    "\n",
    "#### LDA Latent Dirichlet Allocation [LDA Andrew Ng](https://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf), [LDA para mortales](http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/)\n",
    "\n",
    "Este método a diferencia de los antes mencionados asigna una probabilidad de pertenencia a cada tópico por lo que una mismo documento está asociado con diferentes probabilidades a todos los tópicos disponibles. \n",
    "\n",
    "+ Cada término de un documento es asociado a todos los tópicos con cierta probabilidad (obtenida a través de iterar sobre un EM para norm ales multivariadas —Distribución Dirichlet—)\n",
    "+ Las variables latentes son los tópicos y son definidos con anticipación por el experto \n",
    "+ Permite obtener de manera automática el tópico al que pertenece un documento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso estándar para minado de texto\n",
    "\n",
    "1. Tokenización: Cada token normalmente es una palabra, aunque también pueden ser n-gramas donde n puede ser palabras (bi-gramas, tri-gramas, etc.) o bien sílabas o letras \n",
    "    + El enunciado: 'Un enunciado ejemplo de tokenización', estaría formado por 5 tokens unigramas: un, enunciado, ejemplo, de, tokenización\n",
    "    + Por 4 tokens bigramas: Un enunciado, enunciado ejemplo, ejemplo de, de tokenización\n",
    "2. Limpieza de tokens: \n",
    "    + Eliminación de signos de puntuación\n",
    "    + Eliminación de números (depende del caso de negocio)\n",
    "    + Eliminación de espacios al inicio/final de palabras\n",
    "    + Pasar a minúsculas\n",
    "3. *Stopwords*. Dependiendo de nuestro problema de negocio generamos una *lista negra* de palabras que no queremos tomar en cuenta en nuestra métrica de relevancia. Generalmente en esta lista ponemos artículos, preposiciones, conjunciones y palabras específicas al problema. \n",
    "Existen varias listas ya creadas para diferentes idiomas, generalmente a estas listas se les pueden agregar palabras propias o eliminar algunas —en R, paquete [tm](https://cran.r-project.org/web/packages/tm/tm.pdf)—\n",
    "    + Inglés genérico [Snowball](http://snowball.tartarus.org/algorithms/english/stop.txt)\n",
    "    + Español genérico [Snowball](http://snowballstem.org/algorithms/spanish/stop.txt)\n",
    "    + Francés [Snowball](http://snowballstem.org/algorithms/french/stop.txt)\n",
    "    + Portugués [Snowball](http://snowballstem.org/algorithms/portuguese/stop.txt)\n",
    "    + Italiano [Snowball](http://snowballstem.org/algorithms/italian/stop.txt)\n",
    "    + Ruso [Snowball](http://snowballstem.org/algorithms/russian/stop.txt)\n",
    "    + Sueco [Snowball](http://snowballstem.org/algorithms/swedish/stop.txt)\n",
    "    + Finlandés [Snowball](http://snowballstem.org/algorithms/finnish/stop.txt)\n",
    "    + Danés [Snowball](http://snowballstem.org/algorithms/danish/stop.txt)\n",
    "    + Noruego [Snowball](http://snowballstem.org/algorithms/norwegian/stop.txt)\n",
    "\n",
    "4. *Stemming*. Proceso **heurístico** en el que se eliminan plurales y cambiando algunas derivaciones esperando modificar palabras que son lo mismo que pueden estar presentes de diferentes manera. En inglés generalmente se ocupa el algoritmo de [Porter](https://tartarus.org/martin/PorterStemmer/)\n",
    "    + Claramente el algoritmo de *stemming* depende del lenguaje en el que se encuentra el problema de negocio. Existen varios algoritmos dependiendo del lenguaje [stemming español, SNOWBALL](http://snowball.tartarus.org/algorithms/spanish/stemmer.html)\n",
    "        + cheque --> chequ\n",
    "        + chequeo --> cheque\n",
    "        + cheques --> chequ\n",
    "    + Español y otros idiomas: librería [CLIPS](http://www.clips.ua.ac.be/pattern) para python 2\n",
    "        \n",
    "5. *Lemmatization*. Proceso formal en el que se obtiene la raíz de una palabra —lema— realizando análisis morfológico.\n",
    "    + Depende del lenguaje se ocupan algoritmos diferentes\n",
    "    + Estos algoritmos están hechos de la mano de lingüístas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#a5d2fb\";>\n",
    "<p>\n",
    "**Los sistemas de IR son dependientes del idioma por lo que se requiere desarrollar uno específico por lenguaje (inclusive por domino): Inglés americano, Inglés británico, Español mexicano, Español Venezolano, etc.**\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejemplo para TF-IDF\n",
    "\n",
    "Tenemos una colección C de 5 documentos $d_{i}$ obtenidos de titulares de [New York Times español](http://www.nytimes.com/es/): \n",
    "\n",
    "$d_{1}:$ Dilma Rousseff se defiende ante sus rivales en el senado: ‘No me silenciarán’\n",
    "\n",
    "$d_{2}:$ El juicio contra Dilma Rousseff, el próximo evento imperdible en Brasil\n",
    "\n",
    "$d_{3}:$ El Senado de Brasil avanza hacia el juicio de Dilma Rousseff\n",
    "\n",
    "$d_{4}:$ El último intento de Dilma Rousseff por volver a la presidencia\n",
    "\n",
    "$d_{5}:$ La destitución de Rousseff revela actitudes discriminatorias hacia las mujeres en Brasil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python version: (2, 7, 9, 'final', 0)\n",
      "IPython version: (2, 4, 1, '')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import IPython\n",
    "9\n",
    "print \"python version: \" + format(sys.version_info[0:30]) +\\\n",
    "\"\\nIPython version: \" + format(IPython.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Dilma Rousseff se defiende ante sus rivales en el senado: 'No me silenciaran'\",\n",
       " 'El juicio contra Dilma Rousseff, el proximo evento imperdible en Brasil',\n",
       " 'El Senado de Brasil avanza hacia el juicio de Dilma Rousseff',\n",
       " 'El ultimo intento de Dilma Rousseff por volver a la presidencia',\n",
       " 'La destitucion de Rousseff revela actitudes discriminatorias hacia las mujeres en Brasil']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = u\"Dilma Rousseff se defiende ante sus rivales en el senado: 'No me silenciarán'\".encode('utf-8')\n",
    "d2 = u'El juicio contra Dilma Rousseff, el próximo evento imperdible en Brasil'.encode('utf-8')\n",
    "d3 = u'El Senado de Brasil avanza hacia el juicio de Dilma Rousseff'.encode('utf-8')\n",
    "d4 = u'El último intento de Dilma Rousseff por volver a la presidencia'.encode('utf-8')\n",
    "d5 = u'La destitución de Rousseff revela actitudes discriminatorias hacia las mujeres en Brasil'.encode('utf-8')\n",
    "\n",
    "#########quitar acentos!, después se vuelve más complicado!\n",
    "def quitar_acentos(doc):\n",
    "    a = doc.replace(\"á\", \"a\")\n",
    "    e = a.replace(\"é\", \"e\")\n",
    "    i = e.replace(\"í\", \"i\")\n",
    "    o = i.replace(\"ó\", \"o\")\n",
    "    u =o.replace(\"ú\", \"u\")\n",
    "    \n",
    "    return u\n",
    "\n",
    "docs_collection = [d1,d2,d3,d4,d5]\n",
    "\n",
    "docs_collection = [quitar_acentos(doc) for doc in docs_collection]\n",
    "docs_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Dilma', 'Rousseff', 'se', 'defiende', 'ante', 'sus', 'rivales', 'en', 'el', 'senado:', \"'No\", 'me', \"silenciaran'\"], ['El', 'juicio', 'contra', 'Dilma', 'Rousseff,', 'el', 'proximo', 'evento', 'imperdible', 'en', 'Brasil'], ['El', 'Senado', 'de', 'Brasil', 'avanza', 'hacia', 'el', 'juicio', 'de', 'Dilma', 'Rousseff'], ['El', 'ultimo', 'intento', 'de', 'Dilma', 'Rousseff', 'por', 'volver', 'a', 'la', 'presidencia'], ['La', 'destitucion', 'de', 'Rousseff', 'revela', 'actitudes', 'discriminatorias', 'hacia', 'las', 'mujeres', 'en', 'Brasil']]\n"
     ]
    }
   ],
   "source": [
    "#tokenizacion\n",
    "def tokenizacion(doc): \n",
    "   return doc.split(\" \")\n",
    "   \n",
    "terms = [tokenizacion(doc) for doc in docs_collection]\n",
    "print terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dilma', 'Rousseff', 'se', 'defiende', 'ante', 'sus', 'rivales', 'en', 'el', 'senado:', \"'No\", 'me', \"silenciaran'\", 'El', 'juicio', 'contra', 'Dilma', 'Rousseff,', 'el', 'proximo', 'evento', 'imperdible', 'en', 'Brasil', 'El', 'Senado', 'de', 'Brasil', 'avanza', 'hacia', 'el', 'juicio', 'de', 'Dilma', 'Rousseff', 'El', 'ultimo', 'intento', 'de', 'Dilma', 'Rousseff', 'por', 'volver', 'a', 'la', 'presidencia', 'La', 'destitucion', 'de', 'Rousseff', 'revela', 'actitudes', 'discriminatorias', 'hacia', 'las', 'mujeres', 'en', 'Brasil'] 58\n"
     ]
    }
   ],
   "source": [
    "#queremos una lista flatten! \n",
    "def lista_flatten(lista):\n",
    "    return [word for sentence in lista for word in sentence]\n",
    "    \n",
    "flattened_terms = lista_flatten(terms)\n",
    "print flattened_terms, len(flattened_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['el', 'en', 'La', 'por', 'a', 'hacia', 'ante', 'actitudes', 'intento', 'juicio', 'revela', \"silenciaran'\", 'defiende', 'proximo', 'contra', 'Senado', 'sus', 'presidencia', 'Rousseff,', 'senado:', 'Brasil', 'mujeres', 'evento', 'Dilma', 'de', 'volver', 'avanza', 'rivales', 'imperdible', 'ultimo', \"'No\", 'las', 'me', 'El', 'la', 'destitucion', 'discriminatorias', 'Rousseff', 'se'] 39\n"
     ]
    }
   ],
   "source": [
    "#queremos solo palabras unicas\n",
    "def palabras_unicas(terms):\n",
    "    return list(set(terms))\n",
    "\n",
    "unique_terms = palabras_unicas(flattened_terms)\n",
    "print unique_terms, len(unique_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#quitar puntuación\n",
    "import string \n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['el', 'en', 'La', 'por', 'a', 'hacia', 'ante', 'actitudes', 'intento', 'juicio', 'revela', 'silenciaran ', 'defiende', 'proximo', 'contra', 'Senado', 'sus', 'presidencia', 'Rousseff ', 'senado ', 'Brasil', 'mujeres', 'evento', 'Dilma', 'de', 'volver', 'avanza', 'rivales', 'imperdible', 'ultimo', ' No', 'las', 'me', 'El', 'la', 'destitucion', 'discriminatorias', 'Rousseff', 'se']\n"
     ]
    }
   ],
   "source": [
    "def eliminar_puntuacion(term):\n",
    "    replace_punctuation = string.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
    "    return term.translate(replace_punctuation)\n",
    "\n",
    "\n",
    "terms_wo_punctuation = [eliminar_puntuacion(term) for term in unique_terms]\n",
    "print terms_wo_punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['el', 'en', 'La', 'por', 'a', 'hacia', 'ante', 'actitudes', 'intento', 'juicio', 'revela', 'silenciaran ', 'defiende', 'proximo', 'contra', 'Senado', 'sus', 'presidencia', 'Rousseff ', 'senado ', 'Brasil', 'mujeres', 'evento', 'Dilma', 'de', 'volver', 'avanza', 'rivales', 'imperdible', 'ultimo', ' No', 'las', 'me', 'El', 'la', 'destitucion', 'discriminatorias', 'Rousseff', 'se']\n"
     ]
    }
   ],
   "source": [
    "#quitar números\n",
    "import re\n",
    "\n",
    "def eliminar_numeros(term):\n",
    "    return re.sub(r'\\d+','',term)\n",
    "\n",
    "terms_wo_numbers = [eliminar_numeros(term) for term in terms_wo_punctuation]\n",
    "print terms_wo_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['el', 'en', 'La', 'por', 'a', 'hacia', 'ante', 'actitudes', 'intento', 'juicio', 'revela', 'silenciaran', 'defiende', 'proximo', 'contra', 'Senado', 'sus', 'presidencia', 'Rousseff', 'senado', 'Brasil', 'mujeres', 'evento', 'Dilma', 'de', 'volver', 'avanza', 'rivales', 'imperdible', 'ultimo', 'No', 'las', 'me', 'El', 'la', 'destitucion', 'discriminatorias', 'Rousseff', 'se']\n"
     ]
    }
   ],
   "source": [
    "#quitar espacios\n",
    "def eliminar_espacios(term):\n",
    "    return term.strip() \n",
    "\n",
    "terms_wo_spaces = [eliminar_espacios(term) for term in terms_wo_numbers]\n",
    "print terms_wo_spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['el', 'en', 'la', 'por', 'a', 'hacia', 'ante', 'actitudes', 'intento', 'juicio', 'revela', 'silenciaran', 'defiende', 'proximo', 'contra', 'senado', 'sus', 'presidencia', 'rousseff', 'senado', 'brasil', 'mujeres', 'evento', 'dilma', 'de', 'volver', 'avanza', 'rivales', 'imperdible', 'ultimo', 'no', 'las', 'me', 'el', 'la', 'destitucion', 'discriminatorias', 'rousseff', 'se']\n"
     ]
    }
   ],
   "source": [
    "#todo a minúsculas\n",
    "def a_minusculas(term):\n",
    "    return term.lower()\n",
    "\n",
    "terms_lower = [a_minusculas(term) for term in terms_wo_spaces]\n",
    "print terms_lower\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hacia', 'ante', 'actitudes', 'intento', 'juicio', 'imperdible', 'proximo', 'rousseff', 'contra', 'presidencia', 'defiende', 'mujeres', 'evento', 'silenciaran', 'senado', 'volver', 'avanza', 'rivales', 'revela', 'ultimo', 'brasil', 'dilma', 'destitucion', 'discriminatorias'] 24\n"
     ]
    }
   ],
   "source": [
    "#stop words\n",
    "my_stop_words = ['el','la','en','de','a','por','se','las','no','me','sus']\n",
    "\n",
    "#eliminar stopwords\n",
    "def eliminar_stopwords(term, stopwords):\n",
    "    return list(set(term) - set(stopwords))\n",
    "\n",
    "\n",
    "terms_wo_stopwords = eliminar_stopwords(terms_lower, my_stop_words)\n",
    "print terms_wo_stopwords, len(terms_wo_stopwords)\n",
    "\n",
    "#stemming\n",
    "#lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hacia', [0, 0, 1, 0, 1]),\n",
       " ('ante', [1, 0, 0, 0, 0]),\n",
       " ('actitudes', [0, 0, 0, 0, 1]),\n",
       " ('intento', [0, 0, 0, 1, 0]),\n",
       " ('juicio', [0, 1, 1, 0, 0]),\n",
       " ('imperdible', [0, 1, 0, 0, 0]),\n",
       " ('proximo', [0, 1, 0, 0, 0]),\n",
       " ('rousseff', [1, 1, 1, 1, 1]),\n",
       " ('contra', [0, 1, 0, 0, 0]),\n",
       " ('presidencia', [0, 0, 0, 1, 0]),\n",
       " ('defiende', [1, 0, 0, 0, 0]),\n",
       " ('mujeres', [0, 0, 0, 0, 1]),\n",
       " ('evento', [0, 1, 0, 0, 0]),\n",
       " ('silenciaran', [1, 0, 0, 0, 0]),\n",
       " ('senado', [1, 0, 1, 0, 0]),\n",
       " ('volver', [0, 0, 0, 1, 0]),\n",
       " ('avanza', [0, 0, 1, 0, 0]),\n",
       " ('rivales', [1, 0, 0, 0, 0]),\n",
       " ('revela', [0, 0, 0, 0, 1]),\n",
       " ('ultimo', [0, 0, 0, 1, 0]),\n",
       " ('brasil', [0, 1, 1, 0, 1]),\n",
       " ('dilma', [1, 1, 1, 1, 0]),\n",
       " ('destitucion', [0, 0, 0, 0, 1]),\n",
       " ('discriminatorias', [0, 0, 0, 0, 1])]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_wo_punctuation = [eliminar_puntuacion(doc) for doc in docs_collection]\n",
    "docs_wo_space = [eliminar_espacios(doc) for doc in docs_wo_punctuation]\n",
    "docs_wo_lower = [a_minusculas(doc) for doc in docs_wo_space]\n",
    "\n",
    "\n",
    "#matriz terminos-documentos\n",
    "def frequency_count(term, words_in_docs):\n",
    "    return [doc.count(term) for doc in words_in_docs]\n",
    "    \n",
    "    \n",
    "#contar la frecuencia de cada termino en cada documento\n",
    "tf = [frequency_count(term, docs_wo_lower) for term in terms_wo_stopwords]\n",
    "zip(terms_wo_stopwords, tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 1, 1, 2, 1, 1, 5, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 4, 1, 1]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def inverse_document_frequency(term, collection):\n",
    "    bidf = [term in doc for doc in collection]\n",
    "    return sum(bidf)\n",
    " \n",
    "df = [inverse_document_frequency(term, docs_wo_lower) for term in terms_wo_stopwords]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hacia', 0.3979400086720376),\n",
       " ('ante', 0.6989700043360189),\n",
       " ('actitudes', 0.6989700043360189),\n",
       " ('intento', 0.6989700043360189),\n",
       " ('juicio', 0.3979400086720376),\n",
       " ('imperdible', 0.6989700043360189),\n",
       " ('proximo', 0.6989700043360189),\n",
       " ('rousseff', 0.0),\n",
       " ('contra', 0.6989700043360189),\n",
       " ('presidencia', 0.6989700043360189),\n",
       " ('defiende', 0.6989700043360189),\n",
       " ('mujeres', 0.6989700043360189),\n",
       " ('evento', 0.6989700043360189),\n",
       " ('silenciaran', 0.6989700043360189),\n",
       " ('senado', 0.3979400086720376),\n",
       " ('volver', 0.6989700043360189),\n",
       " ('avanza', 0.6989700043360189),\n",
       " ('rivales', 0.6989700043360189),\n",
       " ('revela', 0.6989700043360189),\n",
       " ('ultimo', 0.6989700043360189),\n",
       " ('brasil', 0.2218487496163564),\n",
       " ('dilma', 0.09691001300805642),\n",
       " ('destitucion', 0.6989700043360189),\n",
       " ('discriminatorias', 0.6989700043360189)]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(docs_wo_lower)*1.0\n",
    "\n",
    "def idf(term, N):\n",
    "    return math.log10(N/term)\n",
    "\n",
    "\n",
    "idf_values = [idf(term, N) for term in df]\n",
    "zip(terms_wo_stopwords, idf_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#a5d2fb\";>\n",
    "<p>\n",
    "Nota que los términos que aparecen en todos los documentos de la colección tienen asociada una relevancia de 0!! :)\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hacia', [0.0, 0.0, 2.51294159473206, 0.0, 2.51294159473206]),\n",
       " ('ante', [1.430676558073393, 0.0, 0.0, 0.0, 0.0]),\n",
       " ('actitudes', [0.0, 0.0, 0.0, 0.0, 1.430676558073393]),\n",
       " ('intento', [0.0, 0.0, 0.0, 1.430676558073393, 0.0]),\n",
       " ('juicio', [0.0, 2.51294159473206, 2.51294159473206, 0.0, 0.0]),\n",
       " ('imperdible', [0.0, 1.430676558073393, 0.0, 0.0, 0.0]),\n",
       " ('proximo', [0.0, 1.430676558073393, 0.0, 0.0, 0.0]),\n",
       " ('rousseff', [0.0, 0.0, 0.0, 0.0, 0.0]),\n",
       " ('contra', [0.0, 1.430676558073393, 0.0, 0.0, 0.0]),\n",
       " ('presidencia', [0.0, 0.0, 0.0, 1.430676558073393, 0.0]),\n",
       " ('defiende', [1.430676558073393, 0.0, 0.0, 0.0, 0.0]),\n",
       " ('mujeres', [0.0, 0.0, 0.0, 0.0, 1.430676558073393]),\n",
       " ('evento', [0.0, 1.430676558073393, 0.0, 0.0, 0.0]),\n",
       " ('silenciaran', [1.430676558073393, 0.0, 0.0, 0.0, 0.0]),\n",
       " ('senado', [2.51294159473206, 0.0, 2.51294159473206, 0.0, 0.0]),\n",
       " ('volver', [0.0, 0.0, 0.0, 1.430676558073393, 0.0]),\n",
       " ('avanza', [0.0, 0.0, 1.430676558073393, 0.0, 0.0]),\n",
       " ('rivales', [1.430676558073393, 0.0, 0.0, 0.0, 0.0]),\n",
       " ('revela', [0.0, 0.0, 0.0, 0.0, 1.430676558073393]),\n",
       " ('ultimo', [0.0, 0.0, 0.0, 1.430676558073393, 0.0]),\n",
       " ('brasil',\n",
       "  [0.0, 4.507575551943847, 4.507575551943847, 0.0, 4.507575551943847]),\n",
       " ('dilma',\n",
       "  [10.31885115851617,\n",
       "   10.31885115851617,\n",
       "   10.31885115851617,\n",
       "   10.31885115851617,\n",
       "   0.0]),\n",
       " ('destitucion', [0.0, 0.0, 0.0, 0.0, 1.430676558073393]),\n",
       " ('discriminatorias', [0.0, 0.0, 0.0, 0.0, 1.430676558073393])]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf = []\n",
    "for i in range(len(idf_values)):\n",
    "   tf_idf.append([(doc*1.0)/idf_values[i] if idf_values[i] > 0 else 0.0 for doc in tf[i]])\n",
    "\n",
    "zip(terms_wo_stopwords, tf_idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tenemos el query de consulta **\"Arrestan al diputado que estuvo detrás del juicio político contra Dilma\"** ([El Financiero](http://www.elfinanciero.com.mx/mundo/arrestan-al-diputado-que-estuvo-detras-del-juicio-politico-contra-dilma.html)) nuestro TF/IDF devolvería...\n",
    "\n",
    "+ Arrestan = 0\n",
    "+ al = 0 --> deberemos agregarla al stopword!  \n",
    "+ diputado = 0\n",
    "+ que = 0\n",
    "+ estuvo = 0\n",
    "+ detras = 0\n",
    "+ del = 0\n",
    "+ juicio = [0.0, 2.51294159473206, 2.51294159473206, 0.0, 0.0]\n",
    "+ politico = 0\n",
    "+ contra = [0.0, 1.430676558073393, 0.0, 0.0, 0.0]\n",
    "+ dilma = [10.31885115851617,10.31885115851617,10.31885115851617,10.31885115851617,0.0]\n",
    "\n",
    "\n",
    "d1 = $0.0 + 0.0 + 10.31 = 10.31$ \n",
    "\n",
    "d2 = $2.51 + 1.43 + 10.31 = 14.25$ \n",
    "\n",
    "d3 = $2.51 + 0.0 + 10.31 = 12.86$\n",
    "\n",
    "d4 = $0.0 + 0.0 + 10.31= 10.31$\n",
    "\n",
    "d5 = $0.0 + 0.0 + 0.0 = 0.0$\n",
    "\n",
    "Los documentos ordenados por relevancia con respecto a nuestro query: \n",
    "\n",
    "1. d2: \"El juicio contra Dilma Rousseff, el próximo evento imperdible en Brasil\"\n",
    "2. d3: \"El Senado de Brasil avanza hacia el juicio de Dilma Rousseff\"\n",
    "3. d1: \"Dilma Rousseff se defiende ante sus rivales en el senado: 'No me silenciarán'\"\n",
    "4. d4: 'El último intento de Dilma Rousseff por volver a la presidencia'\n",
    "5. d5: 'La destitución de Rousseff revela actitudes discriminatorias hacia las mujeres en Brasil'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q='Arrestan al diputado que estuvo detrás del juicio político contra Dilma'\n",
    "\n",
    "#eliminar acentos\n",
    "q_wo_accents = quitar_acentos(q) \n",
    "#tokenizar\n",
    "q_tokens = tokenizacion(q_wo_accents)\n",
    "q_unique_tokens = palabras_unicas(q_tokens)\n",
    "#eliminar puntuacion\n",
    "q_wo_punctuation = [eliminar_puntuacion(term) for term in q_unique_tokens]\n",
    "#eliminar numeros\n",
    "q_wo_numbers = [eliminar_numeros(term) for term in q_wo_punctuation]\n",
    "#eliminar espacios\n",
    "q_wo_spaces = [eliminar_espacios(term) for term in q_wo_numbers]\n",
    "#a minusculas\n",
    "q_wo_lower = [a_minusculas(term) for term in q_wo_spaces]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si... Scikit learn ya tiene todo esto listo para usarse :P ... PERO los stop words que trae por default son solo para inglés\n",
    "\n",
    "(╯°□°)╯︵ ┻━┻ ... pero puedes pasarle tu propia lista de stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn as sl\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_setting = TfidfVectorizer(encoding='utf-8', strip_accents='unicode',\n",
    "                analyzer='word', lowercase=True, stop_words=my_stop_words,\n",
    "                use_idf=True, min_df=0)\n",
    "\n",
    "tfidf_matrix = tfidf_setting.fit_transform(docs_collection)\n",
    "terms = tfidf_setting.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 21)\t0.438724228779\n",
      "  (0, 20)\t0.353959945346\n",
      "  (0, 19)\t0.209054445715\n",
      "  (0, 18)\t0.438724228779\n",
      "  (0, 7)\t0.247169577713\n",
      "  (0, 5)\t0.438724228779\n",
      "  (0, 1)\t0.438724228779\n",
      "  (1, 19)\t0.200575845628\n",
      "  (1, 16)\t0.420930934444\n",
      "  (1, 13)\t0.339604427513\n",
      "  (1, 11)\t0.420930934444\n",
      "  (1, 9)\t0.420930934444\n",
      "  (1, 7)\t0.237145146058\n",
      "  (1, 4)\t0.420930934444\n",
      "  (1, 3)\t0.281902352559\n",
      "  (2, 20)\t0.406162115569\n",
      "  (2, 19)\t0.239885888381\n",
      "  (2, 13)\t0.406162115569\n",
      "  (2, 10)\t0.406162115569\n",
      "  (2, 7)\t0.283622257004\n",
      "  (2, 3)\t0.337151246047\n",
      "  (2, 2)\t0.503427473235\n",
      "  (3, 23)\t0.469093038892\n",
      "  (3, 22)\t0.469093038892\n",
      "  (3, 19)\t0.223525346452\n",
      "  (3, 15)\t0.469093038892\n",
      "  (3, 12)\t0.469093038892\n",
      "  (3, 7)\t0.2642788356\n",
      "  (4, 19)\t0.189446450964\n",
      "  (4, 17)\t0.397574650037\n",
      "  (4, 14)\t0.397574650037\n",
      "  (4, 10)\t0.320760724316\n",
      "  (4, 8)\t0.397574650037\n",
      "  (4, 6)\t0.397574650037\n",
      "  (4, 3)\t0.266260376685\n",
      "  (4, 0)\t0.397574650037\n"
     ]
    }
   ],
   "source": [
    "print tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La representación es mucho más eficiente pues en lugar de tener una matriz con muchos 0s solo guardamos el lugar y valor de valores diferentes a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silenciaran  -  0.438724228779\n",
      "senado  -  0.353959945346\n",
      "rousseff  -  0.209054445715\n",
      "rivales  -  0.438724228779\n",
      "dilma  -  0.247169577713\n",
      "defiende  -  0.438724228779\n",
      "ante  -  0.438724228779\n",
      "rousseff  -  0.209054445715\n",
      "proximo  -  0.0\n",
      "juicio  -  0.0\n",
      "imperdible  -  0.0\n",
      "evento  -  0.0\n",
      "dilma  -  0.247169577713\n",
      "contra  -  0.0\n",
      "brasil  -  0.0\n",
      "senado  -  0.353959945346\n",
      "rousseff  -  0.209054445715\n",
      "juicio  -  0.0\n",
      "hacia  -  0.0\n",
      "dilma  -  0.247169577713\n",
      "brasil  -  0.0\n",
      "avanza  -  0.0\n",
      "volver  -  0.0\n",
      "ultimo  -  0.0\n",
      "rousseff  -  0.209054445715\n",
      "presidencia  -  0.0\n",
      "intento  -  0.0\n",
      "dilma  -  0.247169577713\n",
      "rousseff  -  0.209054445715\n",
      "revela  -  0.0\n",
      "mujeres  -  0.0\n",
      "hacia  -  0.0\n",
      "discriminatorias  -  0.0\n",
      "destitucion  -  0.0\n",
      "brasil  -  0.0\n",
      "actitudes  -  0.0\n"
     ]
    }
   ],
   "source": [
    "for col in tfidf_matrix.nonzero()[1]:\n",
    "    print terms[col], ' - ', tfidf_matrix[0, col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos con nuestro query de consulta **\"Arrestan al diputado que estuvo detrás del juicio político contra Dilma\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Arrestan al diputado que estuvo detras del juicio politico contra Dilma'"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_wo_accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 13)\t0.575062556088\n",
      "  (0, 7)\t0.401565123442\n",
      "  (0, 4)\t0.712775215773\n"
     ]
    }
   ],
   "source": [
    "response = tfidf_setting.transform([q_wo_accents])\n",
    "print response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "juicio  -  0.575062556088\n",
      "dilma  -  0.401565123442\n",
      "contra  -  0.712775215773\n"
     ]
    }
   ],
   "source": [
    "for col in response.nonzero()[1]:\n",
    "    print terms[col], ' - ', response[0, col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso de Negocio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taxonomía\n",
    "\n",
    "Organización de temas de un dominio específico\n",
    "\n",
    "![](images/taxonomia_ra.png)\n",
    "\n",
    "#### Ontología\n",
    "\n",
    "Es una taxonomía en donde además definimos tipos, propiedades y relaciones entre los miembros de la taxonomía...  se ocupan mucho en NLP para definir contextos y estructuras. Por ejemplo, partes de una oración.\n",
    "\n",
    "#### Problema\n",
    "\n",
    "En una empresa de contenido editorial que tiene marcas de deportes, moda, negocios, noticias, estilo de vida y noticias de celebridades a.k.a. *chismes*, se requiere de:\n",
    "\n",
    "+ etiquetar el contenido para mejorar el SEO basado en las etiquetas generadas por los editores\n",
    "+ recomendar las etiquetas asociadas a un contenido nuevo al momento que el editor guarda el contenido\n",
    "+ identificar el tema en el que es mejor 'podar' una etiqueta para que sea lo *suficientemente* genérico\n",
    "+ clasificar de manera automática las notas editoriales que ya existen\n",
    "+ clasificar de manera automática las notas editoriales al momento de creación —sugerencia de etiquetas—\n",
    "+ organización del contenido editorial existente\n",
    "    + evitar duplicidad \n",
    "    + aprovechar investigaciones de contenidos escritos anteriormente\n",
    "    + ontología de todo el contenido de casa editorial\n",
    "+ ... predicción de éxito en notas (por tema asociado)\n",
    "+ ... brinda más información para identificación de audiencias \n",
    "+ ... sistema de recomendación de contenidos, al lector\n",
    "+ ... sistema de recomendación de contenidos, al editor\n",
    "\n",
    "#### Árbol de etiquetas\n",
    "\n",
    "+ Los editores de la casa editorial hicieron un árbol jerárquico de etiquetas basados en los temas de los que escriben en sus diferentes marcas y en el árbol estándar internacional de noticias [IPTC](http://show.newscodes.org/index.html?newscodes=medtop&lang=en-GB&startTo=Show)\n",
    "+ Tenemos 3,942 etiquetas con 19 temas generales\n",
    "+ Máximo 8 niveles\n",
    "+ En promedio 4 niveles, depende del tema\n",
    "\n",
    "~10k contenidos de diferentes marcas existentes desde el año 2010: moda, noticias, estilo de vida, deportes, *chismes*\n",
    "\n",
    "\n",
    "![](images/treemap_lev1.png)\n",
    "\n",
    "![](images/treemap_lev2_o.png)\n",
    "\n",
    "#### Elementos del IR\n",
    "\n",
    "1. ¿Cuál es la colección?\n",
    "2. ¿Qué tamaño tiene?\n",
    "3. ¿Cuál sería el query de consulta?\n",
    "4. ¿Qué modelo ocupar para medir relevancia?\n",
    "5. Justificación de decisiones tomadas...\n",
    "\n",
    "\n",
    "1. La colección consiste en el árbol jerárquico de etiquetas generado por los editores por lo que cada etiqueta se vuelve un documento\n",
    "2. 3,942 **documentos**\n",
    "3. El query es el contenido que queremos etiquetar\n",
    "4. BM25 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#a5d2fb\";>\n",
    "<p>\n",
    "5. Siempre JUSTIFIQUEN sus tomas de decisiones y déjenlo plasmado en un documento ejecutivo (Rmd). En nuestro caso decidimos *voltear* qué es la colección y qué es el query ya que la tasa de crecimiento del árbol de etiquetas es mucho más lenta que la generación de contenidos, por cada nuevo contenido hay que buscar en ~4k documentos la relevancia en 1 solo query, al revés, por cada nuevo contenido tengo que volver a querear los ~4k etiquetas en >~10k documentos...\n",
    "<br>\n",
    "<br>\n",
    "Si hubieramos tomado el query como la etiqueta estaríamos encontrando los documentos que probablemente están más relacionados a la misma sin embargo, nuestro cambio busca por documento cuál es la etiqueta más relevante... es una sutil diferencia pero ayuda a concebir el problema de manera más orgánica y es muy fácil de comprender para los editores y tomadores de decisión a.k.a. el consejo... CxO's.\n",
    "\n",
    "</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El prototipo fue realizado en R mientras que la puesta en producción utilizó Hadoop y Spring XD como orquestador con un pequeño cluster de 4 máquinas con 8 GB cada una. El tiempo total para etiquetar todo el contenido fue de ~45 min.\n",
    "\n",
    "Si bien en nuestro caso de negocio nuestro contenido ya existía *limpio* (obvio no!) y digitalizado, en muchas ocasiones tendrás que obtener el contenido tu mismo haciendo web scraping [SelectorGadget](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb). R tiene la librería [rvest](https://cran.r-project.org/web/packages/rvest/rvest.pdf) y Python el módulo [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/).\n",
    "\n",
    "![](images/web_scraping.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Cómo sabemos que las etiquetas sugeridas fueron correctas?\n",
    "\n",
    "Una vez que el contenido ha sido etiquetado, se requiere de humanos que verifiquen si la etiqueta y abstracción del tema fue el adecuado. \n",
    "\n",
    "+ En la vida real: No hay personas dispuestas a leer contenidos y ver clasificaciones sin incentivo alguno (generalmente económico) y es por eso que se recomienda implementar al menos 2 modelos y comparar resultados... el mismo equipo debe estar incluido en la revisión de los resultados... y presentar las conclusiones a los principales interesados del producto.\n",
    "+ En nuestro caso: Hicimos revisiones aleatorias de cada marca sin embargo, hasta que el editor consultaba algún contenido específico (por otras razones) verificaba la etiqueta y manda sus comentarios al equipo... O.o\n",
    "+ En el caso ideal: Tendríamos a los expertos de negocio (número impar!) ayudándo a verificar si la etiqueta y abstracción fue la correcta para realizar un voto de expertos... y hacer adecuaciones sobre todo a la parte de abstracción de los temas.\n",
    "\n",
    "![](images/desempeño_modelo.png)\n",
    "\n",
    "\n",
    "### ¿Cómo mejorar el modelo?\n",
    "\n",
    "+ Verificar los parámetros de tuneo del modelo (if any!)\n",
    "+ Permitir tener una opción digital que registre las recomendaciones del dueño del producto una vez que lo está usando o revisando \n",
    "+ Generar un clasificador de texto basado en algoritmos de machine learning... una vez que generamos el set de datos etiquetado a través de un sistema de IR podemos ocupar estos documentos como información para un clasificador y por lo tanto se pueden ocupar los algoritmos de ML correspondientes a clasificación\n",
    "\n",
    "![](images/flujo_nuevas_etiquetas.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados \n",
    "\n",
    "![](images/prop_all.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias \n",
    "\n",
    "- [The Anatomy of a Large-Scale Hypertextual Web Search Engine](http://infolab.stanford.edu/pub/papers/google.pdf)\n",
    "- [Introduction to Information Retrieval](http://nlp.stanford.edu/IR-book/)\n",
    "- [The Stanford Natural Language Processing Group](http://nlp.stanford.edu/)\n",
    "- [Laboratorio de Lenguaje Natural y Procesamiento de Texto, IPN](http://nlp.cic.ipn.mx/lab-Spanish.htm)\n",
    "- [Grupo de Ingeniería Lingüística (GIL), UNAM](http://grupos.iingen.unam.mx/iling/es-mx/Paginas/default.aspx)\n",
    "- [Deep learning para Clasificación de texto con tensor flow]( http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets para jugar \n",
    "\n",
    "- [Hillary Clinton emails, Kaggle](https://www.kaggle.com/kaggle/hillary-clinton-emails)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
